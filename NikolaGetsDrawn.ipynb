{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Nikola GetsDrawn</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a python script to generate the website GetsDrawn. It takes data from /r/RedditGetsDrawn and makes something awesome. It uses the Nikola web framework in to make a website that is mobile friendly. \n",
    "\n",
    "The script has been rewritten several times and developed over time \n",
    "\n",
    "The first script for rgdsnatch was written after I got banned from posting my artwork on /r/RedditGetsDrawn. The plan was to create a new site that displayed stuff from /r/RedditGetsDrawn. \n",
    "\n",
    "Currently it only displays the most recent 25 items on redditgetsdrawn. The script looks at the newest 25 reference photos on RedditGetsDrawn. It focuses only on jpeg/png images and ignores and links to none .jpg or .png ending files. \n",
    "It is needed to instead of ignoring them files - get the image or images in some cases, from the link.\n",
    "The photos are always submitted from imgur.\n",
    "Still filter out the i.imgur files, but take the links and filter them through a python imgur module returning the .jpeg or .png files. \n",
    "\n",
    "\n",
    "This is moving forward from rgdsnatch.py because I am stuck on it.  \n",
    "\n",
    "TODO\n",
    "\n",
    "Fix the links that don't link to png/jpeg and link to webaddress. \n",
    "Needs to get the images that are at that web address and embed them.\n",
    "\n",
    "Display artwork submitted under the images. \n",
    "\n",
    "Upload artwork to user. Sends them a message on redditgetsdrawn with links. \n",
    "\n",
    "More pandas\n",
    "\n",
    "Saves reference images to imgs/year/month/day/reference/username-reference.png\n",
    "\n",
    "Saves art images to imgs/year/month/day/art/username-line-bw-colour.png \n",
    "\n",
    "Creates index.html file with:\n",
    "Title of site and logo: GetsDrawn\n",
    "Last updated date and time. \n",
    "\n",
    "Path of image file /imgs/year/month/day/username-reference.png. \n",
    "(This needs changed to just their username).\n",
    "\n",
    "Save off .meta data from reddit of each photo, saving it to reference folder.\n",
    "username-yrmnthday.meta - contains info such as author, title, upvotes, downvotes.\n",
    "Currently saving .meta files to a meta folder - along side art and reference. \n",
    "\n",
    "Folder sorting system of files. \n",
    "websitename/index.html-style.css-imgs/YEAR(15)-MONTH(2)-DAY(4)/art-reference-meta\n",
    "Inside art folder\n",
    "Currently it generates USERNAME-line/bw/colour.png 50/50 white files. Maybe should be getting art replies from reddit?\n",
    "\n",
    "Inside reference folder\n",
    "Reference fold is working decent. \n",
    "it creates USERNAME-reference.png / jpeg files. \n",
    "\n",
    "Currently saves username-line-bw-colour.png to imgs folder. Instead get it to save to imgs/year/month/day/usernames.png.\n",
    "Script checks the year/month/day and if folder isnt created, it creates it. If folder is there, exit. \n",
    "Maybe get the reference image and save it with the line/bw/color.pngs\n",
    "\n",
    "The script now filters the jpeg and png image and skips links to imgur pages. This needs to be fixed by getting the images from the imgur pages.\n",
    "It renames the image files to the redditor username followed by a -reference tag (and ending with png of course).\n",
    "It opens these files up with PIL and checks the sizes. \n",
    "It needs to resize the images that are larger than 800px to 800px.\n",
    "These images need to be linked in the index.html instead of the imgur altenatives. \n",
    "\n",
    "Instead of the jpeg/png files on imgur they are downloaded to the server with this script. \n",
    "\n",
    "Filter through as images are getting downloaded and if it has been less than certain time or if the image has been submitted before \n",
    "\n",
    "Extending the subreddits it gets data from to cycle though a list, run script though list of subreddits.\n",
    "\n",
    "Browse certain days - Current day by default but option to scroll through other days.\n",
    "\n",
    "Filters - male/female/animals/couples etc\n",
    "Function that returns only male portraits. \n",
    "tags to add to photos. \n",
    "Filter images with tags\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "#import nose\n",
    "import arrow\n",
    "import shutil\n",
    "import subprocess\n",
    "import getpass\n",
    "from google.cloud import translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://www.reddit.com/r/redditgetsdrawn.json'\n",
    "#headers = {\n",
    "#    'User-Agent': 'hammersmake@gmail.com',\n",
    "    # This is another valid field\n",
    "#}\n",
    "\n",
    "#response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getreference(subreddit):\n",
    "    url = 'https://www.reddit.com/r/{}.json'.format(subreddit)\n",
    "    headers = {'User-Agent': 'hammersmake@gmail.com'}\n",
    "    # This is another valid field\n",
    "    return(requests.get(url, headers=headers).json())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs = getreference('redditgetsdrawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenrefernce():\n",
    "    return(len(subjs['data']['children']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenrefernce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listgallery(ldir):\n",
    "    return(os.listdir(ldir + '/galleries'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listgallery('/mnt/c/Users/luke/Documents/zh-artctrl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "totart = len(resjs['data']['children'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ad87ow'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resjs['data']['children'][5]['data']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "allimg = os.listdir('/mnt/c/Users/luke/Documents/zh-artctrl/galleries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/mnt/c/Users/luke/Documents/zh-artctrl/galleries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tota' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0b962d634918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'children'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtota\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'created'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tota' is not defined"
     ]
    }
   ],
   "source": [
    "datet = arrow.now(resjs['data']['children'][tota]['data']['created'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import translate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.cloud import translate\n",
    "\n",
    "# Instantiates a client\n",
    "#translate_client = translate.Client()\n",
    "\n",
    "# The text to translate\n",
    "#text = u'Hello, world!'\n",
    "# The target language\n",
    "#target = 'zh_cn'\n",
    "\n",
    "# Translates some text into Russian\n",
    "#translation = translate_client.translate(\n",
    "#    text,\n",
    "#    target_language=target)\n",
    "\n",
    "#print(u'Text: {}'.format(text))\n",
    "#print(u'Translation: {}'.format(translation['translatedText']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wǒ\n"
     ]
    }
   ],
   "source": [
    "#hanjs = requests.get('https://glosbe.com/transliteration/api?from=Han&dest=Latin&text=我&format=json')\n",
    "#pingzh = hanjs.json()\n",
    "#print(pingzh['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadimgs(wotsubred, ldir):\n",
    "    getreference(wotsubred)\n",
    "    resjs = response.json()\n",
    "    os.chdir(ldir)\n",
    "    \n",
    "    for tota in range(0, lenrefernce()):\n",
    "        if '.jpg' in (resjs['data']['children'][tota]['data']['url']):\n",
    "            idpost = resjs['data']['children'][tota]['data']['id']\n",
    "            authinfo = (resjs['data']['children'][tota]['data']['author'])\n",
    "            datet = arrow.get(resjs['data']['children'][tota]['data']['created'])\n",
    "            translate_client = translate.Client()\n",
    "\n",
    "            transzh = translate_client.translate(resjs['data']['children'][tota]['data']['title'], target_language='zh_cn')\n",
    "            \n",
    "            hanjs = requests.get('https://glosbe.com/transliteration/api?from=Han&dest=Latin&text={}&format=json'.format(transzh['translatedText']))\n",
    "            pingzh = hanjs.json()\n",
    "            #print(pingzh['text'])\n",
    "\n",
    "            #if authinfo + '.png' not in listgallery(ldir):\n",
    "                #print('image not there')\n",
    "            subprocess.call('wget -O galleries/{}.png {}'.format(idpost, resjs['data']['children'][tota]['data']['url']), shell=True)\n",
    "            with open(ldir + '/posts/' + authinfo + '.meta', 'w') as aupos:\n",
    "                aupos.write('.. title: {}\\n.. slug: {}\\n.. date: {}\\n.. tags: tagsz\\n.. link:\\n.. description:\\n.. type: text'.format(idpost, idpost, datet)) \n",
    "\n",
    "            with open(ldir + '/posts/' + authinfo + '.md', 'w') as aumeta:\n",
    "                aumeta.write('# {}\\n\\n![{}]({})\\n\\n{}'.format(authinfo, idpost, '/galleries/' + idpost + '.png', resjs['data']['children'][tota]['data']['title'] + '\\n\\n' + transzh['translatedText'] + '\\n\\n' + pingzh['text']))\n",
    "            #else:\n",
    "            #    pass\n",
    "                #lisnum = (os.listdir(ldir).count(authinfo + '.png'))\n",
    "                #print(type(lisnum))\n",
    "                #lisnew = lisnum + 1 \n",
    "                \n",
    "                #subprocess.call('wget -O {}{}.png {}'.format(authinfo, lisnew, resjs['data']['children'][tota]['data']['url']), shell=True)\n",
    "                #with open(ldir + '/posts/' + authinfo + str(lisnew) + '.meta', 'w') as aupos:\n",
    "                #    aupos.write('.. title: {}\\n.. slug: {}\\n.. date: {}\\n.. tags: tagsz\\n.. link:\\n.. description:\\n.. type: text'.format(authinfo, authinfo, datet)) \n",
    "\n",
    "                #with open(ldir + '/posts/' + authinfo + str(lisnew) + '.md', 'w') as aumeta:\n",
    "                #    aumeta.write('![{}]({})\\n\\n{}'.format(authinfo, '/galleries/' + authinfo + str(lisnew) + '.png', resjs['data']['children'][15]['data']['title']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wǒ bù gǎn xiāng xìn zhè gè redditpage cún zài！ hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā hā！ hé tā yī qǐ huà huà zhēn shì tài bàng le！ tā de míng zì jiào sāi lā。lái zì lù tè dān de wèn hòu;）\n",
      "shuō xīn nián kuài lè tài wǎn le？ ó， kuài lè xīn de yī nián！ wǒ zài xīn de yī nián lǐ chuān zhe wǒ mā mā zuò de。\n",
      "rú guǒ yǒu rén néng xī yǐn wǒ， wǒ huì hěn gāo xìng！ :-)\n",
      "wǒ hěn lè yì bèi xī yǐn！ hěn xiǎng zhī dào nǐ xiǎng chū le shén me:) :)\n",
      "yǒu rén xiǎng huà wǒ kě ài de xiǎo gǒu ma？☺️\n",
      "yǒu xìng qù xī yǐn wǒ de rén ma？ huān yíng suǒ yǒu fēng gé hé quán shì！\n",
      "yǒu rén xiǎng huà wǒ ma？\n",
      "zhè shì wǒ zhāng tiē le wǒ nǚ péng yǒu zuì xǐ huān de zhào piàn， tā jué duì tǎo yàn。wǒ xī wàng kàn dào bèi huà chū lái， suǒ yǒu fēng gé huān yíng！\n",
      "nǐ néng huà wǒ ma？！？！\n",
      "dà jiā hǎo！ yǒu shéi xiǎng yào bǎ wǒ biàn chéng yī jiàn yì shù pǐn？\n",
      "yǒu rén xiǎng huà wǒ ma？ huān yíng suǒ yǒu kuǎn shì\n",
      "wǒ huì xǐ huān wǒ de gǒu de zhào piàn。\n",
      "hāi RGD！ wǒ zhēn de hěn pèi fú zhè gè shè qū， bìng xiǎng zhī dào nǐ men shì fǒu kě yǐ yòng wǒ de yī zhāng gāo jí zhào piàn zuò nǐ de shì:)\n",
      "hāi！ rú guǒ yǒu rén néng cóng wǒ de12nián jí zhèng shì zhōng huà chū wǒ de zhè zhāng zhào piàn， wǒ huì hěn gāo xìng。xiè xiè！\n",
      "hěn xiǎng kàn kàn nǐ néng yòng zhè zhāng zhào piàn zuò xiē shén me。rèn hé kuǎn shì huān yíng。\n",
      "jīn tiān， wǒ dì yī cì qù qián shuǐ， bìng bèi yī tiáo yú jìn xíng le guāng zhào。yǒu rén kě yǐ wèi wǒ huà zhè gè jì yì ma？ huān yíng rèn hé fēng gé， jí shǐ shì jiǎn dān de tú yā yě huì ràng wǒ kāi xīn\n",
      "yǒu rén xiǎng huà wǒ ma？\n",
      "nǐ men qí zhōng yī gè yǒu cái néng de rén néng huà chū wǒ měi lì de qī zi hé sān zhōu dà de nǚ ér ma？\n",
      "wǒ de gǒu Winnie bèi gào zhī jīn tiān yào qù yī tiáo duì gǒu yǒu hǎo de xiǎo dào。qǐng yǒu rén qǐng tā huà chū tā de tián mì ma？\n",
      "zhè shì wǒ de zhào piàn。wǒ hěn xiǎng kàn dào rén men de yì shù。 （zì）\n",
      "zhè shì wǒ zuì xǐ huān de wǒ hé wǒ de māo de zhào piàn， Fela。qǐng bǎ wǒ men chōu chū lái？ 😸\n",
      "wǒ gǎn dǎ dǔ， huì huà huì hěn yǒu qù\n",
      "qī zi hé wǒ qù le guǎn dào， bìng yǔ xì bāo yī qǐ pāi shè le jìng tóu tiān fù。rèn hé rén dōu yǒu líng gǎn？ zhào piàn bù shòu yǐng xiǎng， dàn kě yǐ shǐ yòng nǐ de chuàng zào lì/jīng shén cuò luàn lái suí yì shǐ yòng tā。hěn duō lái zì jiā ná dà de ài。\n"
     ]
    }
   ],
   "source": [
    "downloadimgs('redditgetsdrawn', '/mnt/c/Users/luke/Documents/zh-artctrl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bucket getsdrawn created.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pygcloud.createbucket('getsdrawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploysite(blogdir, syncname):\n",
    "    os.chdir(blogdir)\n",
    "    subprocess.call('nikola build', shell=True)\n",
    "    pygcloud.makebucketsync(syncname, blogdir + '/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploysite('/mnt/c/Users/luke/Documents/zh-artctrl/', 'getsdrawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive']\n"
     ]
    }
   ],
   "source": [
    "#from codeq_nlp_api import CodeqClient\n",
    "\n",
    "#client = CodeqClient(user_id=\"\", user_key=\"\")\n",
    "\n",
    "#text = \"We’d love to see your take on our little zoo family!\"\n",
    "#document = client.analyze(text)\n",
    "\n",
    "#for sentence in document.sentences:\n",
    "#    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Excitement']\n"
     ]
    }
   ],
   "source": [
    "##for sentence in document.sentences:\n",
    "#    print(sentence.emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('raw_sentence', \"We'd love to see your take on our little zoo family!\"), ('position', 0), ('tokens', ['We', \"'d\", 'love', 'to', 'see', 'your', 'take', 'on', 'our', 'little', 'zoo', 'family', '!']), ('tokens_filtered', ['love', 'little', 'zoo', 'family']), ('lemmas', ['we', \"'d\", 'love', 'to', 'see', 'your', 'take', 'on', 'our', 'little', 'zoo', 'family', '!']), ('pos_tags', ['PRP', 'MD', 'VB', 'TO', 'VB', 'PRP$', 'NN', 'IN', 'PRP$', 'JJ', 'NN', 'NN', '.']), ('dependencies', [['love@@@3', \"'d@@@2\", 'aux'], ['love@@@3', '!@@@13', 'punct'], ['love@@@3', 'see@@@5', 'xcomp'], ['love@@@3', 'We@@@1', 'nsubj'], ['take@@@7', 'on@@@8', 'prep'], ['take@@@7', 'your@@@6', 'poss'], ['family@@@12', 'zoo@@@11', 'nn'], ['family@@@12', 'our@@@9', 'poss'], ['family@@@12', 'little@@@10', 'amod'], ['root@@@0', 'love@@@3', 'root'], ['see@@@5', 'take@@@7', 'dobj'], ['see@@@5', 'to@@@4', 'aux'], ['on@@@8', 'family@@@12', 'pobj']]), ('truecase_sentence', \"we 'd love to see your take on our little zoo family !\"), ('detruecase_sentence', \"We 'd love to see your take on our little zoo family !\"), ('speech_act', ['DESIRE/NEED']), ('named_entities', []), ('nes_terms', []), ('nes_types', []), ('nes_positions', []), ('emotions', ['Excitement']), ('sarcastic', 'Non-sarcastic'), ('sentiment', ['Positive']), ('dates', []), ('is_task', 0), ('task_subclassification', []), ('task_actions', []), ('coreferences', [])])\n"
     ]
    }
   ],
   "source": [
    "##for sentence in document.sentences:\n",
    "#    print(sentence.to_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
